import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import datetime

# --- B∆Ø·ªöC 1: K·∫æT N·ªêI & L·∫§Y D·ªÆ LI·ªÜU L·ªäCH S·ª¨ (>= 2 NƒÇM) ---
SHEET_ID = "1eNxCsEEQsh7NEpjuaxdHLsNKM8TBKw-RA4h5FmeMe7Q"
CSV_URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/export?format=csv"

def run_prediction_pipeline():
    try:
        df = pd.read_csv(CSV_URL)
        df.columns = [str(c).strip() for c in df.columns]
        print(f"‚úÖ B∆∞·ªõc 1: ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng. T·ªïng s·ªë d√≤ng th√¥: {len(df)}")
    except Exception as e:
        print(f"‚ùå L·ªói: {e}")
        return

    # --- B∆Ø·ªöC 2: TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU ---
    # X√°c ƒë·ªãnh c·ªôt Ng√†y v√† Gi√° (D·ª±a tr√™n c·∫•u tr√∫c file c·ªßa b·∫°n)
    date_col = 'Ng√†nh' if 'Ng√†nh' in df.columns else df.columns[0]
    price_col = next((c for c in df.columns if "Gi√° ƒê√≥ng" in c or "Close" in c), None)
    
    df[date_col] = pd.to_datetime(df[date_col], dayfirst=True, errors='coerce')
    
    # L√†m s·∫°ch s·ªë: ƒë·ªïi d·∫•u ph·∫©y sang d·∫•u ch·∫•m (chu·∫©n VN -> qu·ªëc t·∫ø)
    def clean_price(val):
        s = str(val).replace(',', '.')
        return pd.to_numeric(s, errors='coerce')

    df['Close'] = df[price_col].apply(clean_price)
    
    # Lo·∫°i b·ªè "r√°c": Gi√° PEPE th·∫≠t lu√¥n < 0.1 USD (lo·∫°i b·ªè c·ªôt NƒÉm b·ªã nh·∫ßm)
    df = df[df['Close'] < 0.1].dropna(subset=[date_col, 'Close']).sort_values(by=date_col)
    print(f"‚úÖ B∆∞·ªõc 2: Ti·ªÅn x·ª≠ l√Ω xong. D·ªØ li·ªáu s·∫°ch: {len(df)} d√≤ng.")

    # --- B∆Ø·ªöC 3: T·∫†O ƒê·∫∂C TR∆ØNG (LAG / INDICATORS) ---
    # 1. ƒê·∫∑c tr∆∞ng tr·ªÖ (Lag 1 ng√†y)
    df['lag_1'] = df['Close'].shift(1)
    # 2. Ch·ªâ b√°o SMA (Trung b√¨nh ƒë·ªông 7 ng√†y)
    df['SMA_7'] = df['Close'].rolling(window=7).mean()
    # 3. Ch·ªâ b√°o RSI (S·ª©c m·∫°nh t∆∞∆°ng ƒë·ªëi 14 ng√†y)
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / (loss + 1e-9)
    df['RSI'] = 100 - (100 / (1 + rs))
    
    df = df.dropna().reset_index(drop=True)
    print("‚úÖ B∆∞·ªõc 3: ƒê√£ t·∫°o ƒë·∫∑c tr∆∞ng Lag, SMA v√† RSI.")

    # --- B∆Ø·ªöC 4: CHIA TRAIN - TEST THEO TH·ªúI GIAN ---
    # T·ª∑ l·ªá: 80% d·ªØ li·ªáu c≈© ƒë·ªÉ h·ªçc, 20% d·ªØ li·ªáu m·ªõi nh·∫•t ƒë·ªÉ ki·ªÉm tra
    split_idx = int(len(df) * 0.8)
    train_df = df.iloc[:split_idx]
    test_df = df.iloc[split_idx:]
    
    feature_cols = ['Close', 'lag_1', 'SMA_7', 'RSI']
    scaler = MinMaxScaler()
    train_scaled = scaler.fit_transform(train_df[feature_cols])
    test_scaled = scaler.transform(test_df[feature_cols])

    def create_xy(data, lookback=15):
        X, y = [], []
        for i in range(lookback, len(data)):
            X.append(data[i-lookback:i])
            y.append(data[i, 0])
        return np.array(X), np.array(y)

    lookback = 15
    X_train, y_train = create_xy(train_scaled, lookback)
    X_test, y_test = create_xy(test_scaled, lookback)
    print("‚úÖ B∆∞·ªõc 4: ƒê√£ chia d·ªØ li·ªáu Train/Test theo th·ªùi gian.")

    # --- B∆Ø·ªöC 5: HU·∫§N LUY·ªÜN M√î H√åNH (LSTM) ---
    model = Sequential([
        LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
        Dropout(0.2),
        LSTM(32),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse')
    print("üöÄ B∆∞·ªõc 5: AI ƒëang h·ªçc t·ª´ l·ªãch s·ª≠ gi√°...")
    model.fit(X_train, y_train, epochs=40, batch_size=32, verbose=0)

    # --- B∆Ø·ªöC 6: D·ª∞ ƒêO√ÅN ---
    y_pred_scaled = model.predict(X_test, verbose=0)
    
    # ƒê∆∞a v·ªÅ gi√° tr·ªã th·ª±c t·∫ø (Inverse Scaling)
    def invert(scaled_val):
        dummy = np.zeros((len(scaled_val), len(feature_cols)))
        dummy[:, 0] = scaled_val.flatten()
        return scaler.inverse_transform(dummy)[:, 0]

    y_pred = invert(y_pred_scaled)
    y_actual = invert(y_test.reshape(-1, 1))
    print("‚úÖ B∆∞·ªõc 6: Ho√†n th√†nh d·ª± ƒëo√°n tr√™n t·∫≠p Test.")

    # --- B∆Ø·ªöC 7: ƒê√ÅNH GI√Å & TR·ª∞C QUAN H√ìA ---
    mae = mean_absolute_error(y_actual, y_pred)
    rmse = np.sqrt(mean_squared_error(y_actual, y_pred))
    print(f"\nüìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å:\n- MAE: {mae:.10f}\n- RMSE: {rmse:.10f}")

    # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh
    plt.figure(figsize=(12, 6))
    plt.style.use('dark_background')
    test_dates = test_df[date_col].values[lookback:]
    
    plt.plot(test_dates, y_actual, label='Gi√° Th·ª±c T·∫ø (Actual)', color='cyan', lw=2)
    plt.plot(test_dates, y_pred, label='AI D·ª± ƒêo√°n (Predicted)', color='yellow', ls='--')
    
    plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.8f'))
    plt.title('B√ÅO C√ÅO D·ª∞ B√ÅO PEPE - QUY TR√åNH 7 B∆Ø·ªöC', color='lime', fontsize=15)
    plt.legend()
    plt.grid(alpha=0.2)
    plt.xticks(rotation=30)
    plt.show()

# Th·ª±c thi
run_prediction_pipeline()